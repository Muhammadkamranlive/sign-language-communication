# End to End Sign-Language Communication
This repository is about end to end communication between physically hearing impairment(person1) and outer world(person2).

from person1 to person2:
<br>
1.person 2 records the video of signs generated by person1.
<br>
2.the video is split into frames and body poses are taken from the frames. 
<br>
3.from body points and locations we map the sign gloss.
<br>
4.from sign gloss to english is translated through NLP techniques.

## NLP techniques output ##
The results I achieved below are taken dataset from phenoix weather dataset for sign langauge by using Luong's attension based mechanism.
<br>

**german to gloss **

![germantogloss](https://user-images.githubusercontent.com/48018142/66399424-36fc1a80-e9fd-11e9-84a6-3f0a8017fd61.JPG)


**gloss to german**

![glosstogerman](https://user-images.githubusercontent.com/48018142/66399425-36fc1a80-e9fd-11e9-9f7d-4155823d8f64.JPG)
<br>
resources: 
<br>
<br> https://github.com/tensorflow/nmt/tree/tf-1.2<br>
<br>https://github.com/neccam/nslt.<br>





## Video generation using GAN. ##

![out1](https://user-images.githubusercontent.com/48018142/70058448-eec83580-1604-11ea-97b3-264f7d35908b.png)
![out2](https://user-images.githubusercontent.com/48018142/70058449-eec83580-1604-11ea-8281-e59b36c2e8a5.png)

